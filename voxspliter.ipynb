{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# this methode finds the indices for all occurencys of target in data \n",
    "def findAll(data: bytes, target: int) -> list:\n",
    "    result = []\n",
    "    last_index = 0\n",
    "    while last_index != -1:\n",
    "        i = data[last_index:].find(target)\n",
    "        if(i < 0):\n",
    "            return result\n",
    "        else:\n",
    "            result += [last_index+i]\n",
    "            last_index = last_index+i+1\n",
    "            \n",
    "# this methode finds the indices for all occurencys of a word in data \n",
    "def findKeyword(data, word):\n",
    "    word_array = word.encode('ascii')\n",
    "    result = []\n",
    "    possible_indices = findAll(data, word_array[0])\n",
    "    for p in possible_indices:\n",
    "        same = True\n",
    "        for i in range(1, len(word)):\n",
    "            if(data[p+i] != word_array[i]):\n",
    "                same = False\n",
    "        if(same):\n",
    "            result += [p]\n",
    "    return result\n",
    "\n",
    "def distance(a, b):\n",
    "    return math.sqrt(pow(a[0]-b[0],2)+pow(a[1]-b[1],2)+pow(a[2]-b[2],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name: str) -> bytes:\n",
    "    binary_file = open(name, 'rb')\n",
    "    data = binary_file.read()\n",
    "    binary_file.close()\n",
    "    return data\n",
    "\n",
    "def save(data: bytes, name: str):\n",
    "    f = open(name, 'wb+')\n",
    "    f.write(data)\n",
    "    f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIZE\\0c 00 00 00 \\ 00 00 00 00 \\ 03 00 00 00 \\ 03 00 00 00 \\ 03 00 00 00 \\ XYZI \\54 00 00 00 \\ 00 00 00 00 \\ 14 00 00 00'\\\n",
    "# id                                 size x       size y         size z      id                                 # voxel   \n",
    "\n",
    "# |SIZE|#bytes|#children|size x|size y|size z|XYZI|#bytes|#childeren|#voxel n|[x y z c]|...|[x y z c]|\n",
    "# ^start_id                                  ^xyz_id                         ^vox_id    ^[x y z c]*n ^end_id\n",
    "\n",
    "def toBytes(a: int) -> bytes:\n",
    "    return a.to_bytes(4, byteorder=\"little\")\n",
    "\n",
    "# takes data in for [[a_1,a_2,...],[b_1,b_2,...],...] and turns it into a byte array (a_n,b_n,... <256)\n",
    "def toBytearray(data) -> bytes:\n",
    "    byte = bytearray()\n",
    "    for d in data:\n",
    "        for i in d:\n",
    "            byte += (i).to_bytes(1, byteorder=\"little\")\n",
    "    return byte\n",
    "\n",
    "def sizeChunk(x: int, y: int, z: int) -> bytes:\n",
    "    result = bytearray()\n",
    "    result.extend(map(ord, \"SIZE\"))\n",
    "    result += toBytes(12) + toBytes(0) + toBytes(x) + toBytes(y) + toBytes(z)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def xyziChunk(voxel) -> bytes:\n",
    "    n = len(voxel)\n",
    "    result = bytearray()\n",
    "    result.extend(map(ord, \"XYZI\"))\n",
    "    result += toBytes(4+n*4) + toBytes(0) + toBytes(n) + toBytearray(voxel)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def maxDimensions(voxel):\n",
    "    result = [0,0,0]\n",
    "    for v in voxel:\n",
    "        for i in range(0, len(result)):\n",
    "            result[i] = max(result[i], v[i])\n",
    "            \n",
    "    return result\n",
    "\n",
    "def modelDataAutoSize(voxel) -> bytes:\n",
    "    result = bytearray()\n",
    "    dimensions = maxDimensions(voxel)\n",
    "    result += sizeChunk(dimensions[0]+1,dimensions[1]+1,dimensions[2]+1)\n",
    "    result += xyziChunk(voxel)\n",
    "    return result\n",
    "\n",
    "def modelData(voxel, x: int, y: int, z: int) -> bytes:\n",
    "    result = bytearray()\n",
    "    result += sizeChunk(x,y,z)\n",
    "    result += xyziChunk(voxel)\n",
    "    return result\n",
    "\n",
    "def packChunk(number_of_models: int):\n",
    "    result = bytearray()\n",
    "    result.extend(map(ord, \"PACK\"))\n",
    "    result += toBytes(4) + toBytes(0) + toBytes(number_of_models*2)\n",
    "    return result\n",
    "\n",
    "def mainHeader(byte_size: int) -> bytes:\n",
    "    result = bytearray()\n",
    "    result.extend(map(ord, \"VOX \"))\n",
    "    result += toBytes(150)\n",
    "    result.extend(map(ord, \"MAIN\"))\n",
    "    result += toBytes(0) + toBytes(byte_size) \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(filename: str, num_clusters: int):\n",
    "    # Read the whole file at once\n",
    "    data = load(filename)\n",
    "    model_ids = findKeyword(data, 'SIZE') \n",
    "\n",
    "    header = data[:model_ids[0]]\n",
    "\n",
    "    model_bytes = bytearray()\n",
    "    end_id=0\n",
    "    voxel=[]\n",
    "    \n",
    "    for m_id in model_ids:\n",
    "        #calculate section start ids and length\n",
    "        xyz_id = m_id+24\n",
    "        vox_id = xyz_id+16\n",
    "        n = int.from_bytes(data[xyz_id+12:vox_id], byteorder = \"little\")\n",
    "        end_id = vox_id + n*4\n",
    "\n",
    "        #seperate header from voxel\n",
    "        voxel += [[data[vox_id+i*4], data[vox_id+1+i*4], data[vox_id+2+i*4], data[vox_id+3+i*4]] for i in range(0, n)]\n",
    "\n",
    "    #split\n",
    "    dimensions = maxDimensions(voxel)\n",
    "    centers = [[random.randrange(0,dimensions[0]),random.randrange(0,dimensions[1]),random.randrange(0,dimensions[2]),7+i] for i in range(0,num_clusters)]\n",
    "    cluster = [[] for i in range(0,len(centers))]\n",
    "    for v in voxel:\n",
    "        center_id = 0\n",
    "        col = 80\n",
    "        dist = 1000000;\n",
    "        min_i = 0\n",
    "        for i in range(0,len(centers)):\n",
    "            d = distance(centers[i][0:3],v[0:3])\n",
    "            if(d<dist):\n",
    "                dist = d\n",
    "                min_i = i\n",
    "        cluster[min_i] += [v]\n",
    "\n",
    "    #seperate header and tail, read number of voxels n\n",
    "    tail = data[end_id:]\n",
    "\n",
    "    rgba_id = findKeyword(data, 'RGBA')[0]\n",
    "\n",
    "    rgba_chunk = data[rgba_id:rgba_id+12+1024]\n",
    "    for i in range(0,len(cluster)):\n",
    "\n",
    "        body = modelData(cluster[i],dimensions[0]+1, dimensions[1]+1, dimensions[2]+1) + rgba_chunk\n",
    "\n",
    "        #calculate endresult\n",
    "        result = mainHeader(len(body)) + body\n",
    "        save(result, filename[:len(filename)-4] + str(i) + \".vox\")\n",
    "    \n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'C:\\\\Users\\\\TIm\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-991de134-79aa-4883-81f9-d7a56b05fa28.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-768c4c3f6cdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Arguments missing, use 'py -3.6 voxspliter.px <file name> <number of clusters>'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'C:\\\\Users\\\\TIm\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-991de134-79aa-4883-81f9-d7a56b05fa28.json'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if(len(sys.argv)>=3):\n",
    "    split(str(sys.argv[1]), int(sys.argv[2]))\n",
    "else:\n",
    "    print(\"Arguments missing, use 'py -3.6 voxspliter.px <file name> <number of clusters>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tkinter as tk\n",
    "#from tkinter import filedialog\n",
    "#from tkinter import simpledialog\n",
    "\n",
    "#root = tk.Tk()\n",
    "\n",
    "#file_path = filedialog.askopenfilename()\n",
    "\n",
    "#USER_INP = simpledialog.askstring(title=\"VOX Splitter\",\n",
    "#                                  prompt=\"How many pieces do you want?:\")\n",
    "\n",
    "#split(file_path,int(USER_INP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "split(\"cube.vox\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
